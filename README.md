The steps followed in order are available here 
# Project README
![Model Status]()
## DVC Setup
- Install the DVC Windows bit version from the dvc website. 
- Run the setup and give it all necessary permissions.
- Add dvc.exe to the system's path variables in the environment variables.
- Restart your computer.
- Install the DVC VSCode extension from the vscode store.
- Navigate to the project directory, open VSCode there, and make sure the folder is a Git repository created by Git or GitHub Desktop.
- Open the VSCode terminal and run the following command:    dvc init
  to initialize your dvc repository.
- Press F1, search for "DVC: show setup," and click on it.
- If there's a green tick or warning sign next to the DVC logo, it indicates that your DVC installation has completed successfully.
- Run the data generator file "random_data.py" to get the data file "dummy_sensor_data.csv":
    python random_data.py
- If 'dummy_sensor_data.csv' is being tracked by Git, hand it over to DVC via:
    dvc add dummy_sensor_data.csv
- Add the Google Drive identifier to the DVC config file in the .dvc folder.
    init
    [core]
        remote = storage
    ['remote "storage"']
        url = gdrive://XYsafskkskf...
- Save the file and commit the changes.
- Push the data to Google Drive:
    dvc push
- Check the DVC setup:
    dvc remote storage

## Requirements.txt
Contains the list of required libraries/dependencies.

## Workflow
Holds the automation of all the required tasks. I.e: 
  1. DVC
  2. MLFLOW
  3. Concept Drift
  4. Docker Containerization
## Code Flow
The code flow is as follows:
  1. random_data.py is run to give our base data
  2. This gets preprocessed by preprocess_data.py
  3. The csv files generated by both these processes end up with DVC.
  4. preprocess_data.py is called by the train.py function which trains the first model implementation and pushes to mlflow server.
  5. The monitor function ensures that the models performance is satisfactory otherwise it retrains using the training code and updates the model on mlflow
  6. All these tasks keep automated by github actions therefore in case of model deterioration-- the updated images etc will be pushed to docker and all other respective places.

## Tasks Implementation
A split of the work division between the three group members.

## Important Tasks: 
1. set up Google Auto-Authentication for the credential API
2. MLFlow Remote Server setup for github through Dagshub
3. Set up Github Actions and Secrets

## Public Access Link
Anyone can view models and experiment data using the following link:
https://dagshub.com/mlopsdeadinside/project.mlflow/

The data is maintained by DVC on:
https://drive.google.com/drive/u/3/folders/15GZfZkoJqOejtSSEVedx9m75NZTRMATC

The Dockerfile is maintained on: 
https://hub.docker.com/repository/docker/mlopsdeadinside/project/general
